{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network visualization\n",
    "\n",
    "This project attempts to create a network of collaboration among the top-100 patent holders, using OECD HAN and RegPat databases, with the European Patents Office records.\n",
    "\n",
    "link to gitHub repository:\n",
    "https://github.com/dvasques83/medsci736\n",
    "\n",
    "Files on:\n",
    "~/Dropbox (Complex systems)/PhD Documents/Projects/6-patents_data/innovation-networks$\n",
    "\n",
    "Also on Google Drive:\n",
    "https://drive.google.com/drive/u/1/folders/0BzSi2MopfPaXanlNcGltSmlnZ00\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwt\n",
    "import csv\n",
    "from itertools import izip_longest\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import psycopg2 as pg\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get the data and return array with data\n",
    "def query_han_patents():  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    #CONNECT TO POSTGRESQL\n",
    "    connection_string = \"host= 'localhost' dbname='postgres' user='postgres' password=''\"\n",
    "    conn = pg.connect(connection_string)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    #Patent Number\n",
    "    patent_nbr_query = \"SELECT patent_number FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(patent_nbr_query)\n",
    "    patent_nbr_list = cur.fetchall()\n",
    "    #print 'The length of patents list is: ' + str(len(patent_nbr_list))\n",
    "    \n",
    "    #HAN ID\n",
    "    han_id_query = \"SELECT han_id FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(han_id_query)\n",
    "    han_id_list = cur.fetchall()\n",
    "    #print 'The length of han id list is: ' + str(len(han_id_list))\n",
    "    \n",
    "    #Clean name\n",
    "    clean_name_query = \"SELECT clean_name FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(clean_name_query)\n",
    "    clean_name_list = cur.fetchall()\n",
    "    #print 'The length of clean name list is: ' + str(len(clean_name_list))\n",
    "\n",
    "    #Country code\n",
    "    ctry_code_query = \"SELECT ctry_code FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(ctry_code_query)\n",
    "    ctry_code_list = cur.fetchall()\n",
    "    #print 'The length of country code list is: ' + str(len(ctry_code_list))\n",
    "    \n",
    "    #IPC\n",
    "    ipc_query = \"SELECT ipc FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(ipc_query)\n",
    "    ipc_list = cur.fetchall()\n",
    "    #print 'The length of IPC list is: ' + str(len(ipc_list))\n",
    "    \n",
    "    #Application year\n",
    "    app_year_query = \"SELECT app_year FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(app_year_query)\n",
    "    app_year_list = cur.fetchall()\n",
    "    #print 'The length of application year list is: ' + str(len(app_year_list))\n",
    "    \n",
    "    appln_pathan_array = np.column_stack((patent_nbr_list, han_id_list, clean_name_list, ctry_code_list, ipc_list, app_year_list))\n",
    "    \n",
    "    print 'Running time to query: ' + str(time.time() - t0)\n",
    "    \n",
    "    cur.close()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return appln_pathan_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_array():\n",
    "    \n",
    "    appln_pathan_array = query_han_patents()\n",
    "    \n",
    "    df = pd.DataFrame(data=appln_pathan_array, columns=['patent number','han_id','name','country','ipc code','year'])\n",
    "    df_unique = df.drop_duplicates()\n",
    "    \n",
    "    patent_number = df_unique['patent number'].values.tolist()\n",
    "    han_id = df_unique['han_id'].values.tolist()\n",
    "    name = df_unique['name'].values.tolist()\n",
    "    country = df_unique['country'].values.tolist()\n",
    "    ipc = df_unique['ipc code'].values.tolist()\n",
    "    year = df_unique['year'].values.tolist()\n",
    "    \n",
    "    data = np.column_stack((patent_number, han_id, name, country, ipc, year))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network(appln_pathan_array):\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #CREATE NETWORK\n",
    "    B = nx.Graph()\n",
    "    for patent in appln_pathan_array:\n",
    "        B.add_node(patent[0], bipartite=0, year=patent[5])\n",
    "        B.add_node(patent[1], bipartite=1, name=str(patent[2]), ctry=str(patent[3]))\n",
    "        B.add_edge(patent[0], patent[1])\n",
    "\n",
    "    print 'Running time to create network: ' + str(time.time() - t0)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def more500_bipnetwork(data):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    B = create_network(data)\n",
    "    \n",
    "    top_nodes = set(node for node,d in B.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B) - top_nodes #klist\n",
    "    #deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary\n",
    "    \n",
    "    B500 = B.copy()\n",
    "    \n",
    "    for node in bottom_nodes:\n",
    "        if B.degree(node) < 501:\n",
    "            B500.remove_node(node)\n",
    "            \n",
    "    top_nodes = set(node for node,d in B500.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B500) - top_nodes #klist \n",
    "    \n",
    "    return B, top_nodes, bottom_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#projected network of companies with more than 500 patents\n",
    "\n",
    "def more500_copatenting(B500):\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    #BIPARTITE NETWORK        \n",
    "    top_nodes = set(node for node,d in B500.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B500) - top_nodes #klist\n",
    "    #deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary\n",
    "    \n",
    "           \n",
    "    #WEIGHTED PROJECTED NETWORK\n",
    "    G_w = bipartite.weighted_projected_graph(B500,bottom_nodes)\n",
    "    \n",
    "    print 'Running time to create projection: ' + str(time.time() - t0)\n",
    "    \n",
    "    return G_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create bipartite network with patents as top nodes (code 0) and applicants as bottom nodes (code 1)\n",
    "#patents have attributes year and ipc\n",
    "#applicants have attributes name, country, year and ipc\n",
    "\n",
    "def create_network(appln_pathan_array):\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #CREATE NETWORK\n",
    "    B = nx.Graph()\n",
    "    t = 0\n",
    "    \n",
    "    for record in appln_pathan_array:\n",
    "        if record[0] in B.nodes():\n",
    "            B.node[record[0]]['ipc'].append(record[4])\n",
    "        else:\n",
    "            B.add_node(record[0], bipartite=0, year=record[5], ipc=[record[4]])\n",
    "            \n",
    "        if record[1] in B.nodes():\n",
    "            B.node[record[1]]['year'].append(record[5])\n",
    "            B.node[record[1]]['ipc'].append(record[4])\n",
    "        else:    \n",
    "            B.add_node(record[1], bipartite=1, name=str(record[2]), ctry=str(record[3]), year=[record[5]], ipc=[record[4]])\n",
    "            \n",
    "        #if (record[0], record[1]) not in B.edges():    \n",
    "        B.add_edge(record[0], record[1])\n",
    "        t += 1\n",
    "        if t % 1000 == 0:\n",
    "            print t\n",
    "\n",
    "    print 'Running time to create network: ' + str(time.time() - t0)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to query: 63.6329228878\n"
     ]
    }
   ],
   "source": [
    "#call function that query data and create array with all data\n",
    "data = unique_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to create network: 59.6463849545\n"
     ]
    }
   ],
   "source": [
    "B = create_network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_nodes = set(node for node,d in B.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "bottom_nodes = set(B) - top_nodes #klist\n",
    "#deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BIPARTITE NETWORK WITH MORE THAN 500 PATENTS\n",
    "B500 = B.copy()\n",
    "    \n",
    "for node in bottom_nodes:\n",
    "    if B.degree(node) < 501:\n",
    "        B500.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to create projection: 21.3102178574\n"
     ]
    }
   ],
   "source": [
    "G_w = more500_copatenting(B500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_nodes500 = set(node for node,d in B500.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "bottom_nodes500 = set(B500) - top_nodes #klist\n",
    "#deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10,1):\n",
    "    print G_w.edges(data=True)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print G_w.edges(data=True)[3][2]['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a json file with node and link information from pandas unique dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsonfile = open(\"co-patenting500.json\", \"wb\")\n",
    "\n",
    "#create nodes\n",
    "print >> jsonfile, \"{\"\n",
    "print >> jsonfile, '\"nodes\": ['\n",
    "\n",
    "for node in bottom_nodes500:\n",
    "    print >> jsonfile, '{\"id\": '+str(B500.node[node]['name'])+', '+\\\n",
    "                        '\"group\": '+str(B500.node[node]['ctry'])+', '+\\\n",
    "                        '\"bipdegree\": '+str(B500.degree(node))+', '\\\n",
    "                        '\"projdegree\": '+str(G_w.degree(node))+'}'\n",
    "\n",
    "print >> jsonfile, '],'\n",
    "print >> jsonfile, '\"links\": ['\n",
    "\n",
    "for link in G_w.edges(data=True):\n",
    "    print >> jsonfile, '{\"source\": '+str(B500.node[link[0]]['name'])+', '+\\\n",
    "                        '\"target\": '+str(B500.node[link[1]]['name'])+', '+\\\n",
    "                        '\"value\": '+str(link[2]['weight'])+'}'\n",
    "            \n",
    "print >> jsonfile, '],'\n",
    "print >> jsonfile, '}'\n",
    "jsonfile.close()             \n",
    "    \n",
    "#jsonfile.write('\\n,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
